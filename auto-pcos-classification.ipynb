{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ddFrI3iD1gm",
        "outputId": "435dda30-ba1b-4975-9f71-d7d521c68aa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "# pip install tqdm\n",
        "!pip install scikit-image\n",
        "!pip  install openpyxl\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "# !pip install -U scikit-image\n",
        "from joblib import dump, load\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import torch\n",
        "model_clip = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor_clip = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "W1NLDPJXGS0k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "1jPw_FCuD1gv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# BASE_DIR = os.path.dirname(os.path.join(os.path.dirname(__file__), 'pcos'))\n",
        "# print(\"Base Dir:\", BASE_DIR)\n",
        "training_dataset_path = '/content/drive/MyDrive/data/input/PCOSGen-train'\n",
        "test_dataset_path = '/content/drive/MyDrive/data/input/PCOSGen-test/images/'\n",
        "label_path ='/content/drive/MyDrive/data/input/class_label.xlsx'\n",
        "data_dir = '/content/drive/MyDrive/data/output'\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "val_dir = os.path.join(data_dir, 'val')\n",
        "train_labels_path = os.path.join(data_dir, 'train_labels.csv' )\n",
        "val_labels_path = os.path.join(data_dir, 'val_labels.csv' )\n",
        "models_path = os.path.join(data_dir, 'models')\n",
        "plot_dir = os.path.join(data_dir, 'plots')\n",
        "os.makedirs(models_path, exist_ok=True)\n",
        "os.makedirs(plot_dir, exist_ok=True)\n",
        "result_submission_file =  os.path.join(data_dir, 'result_submission.xlsx' )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "sojFhAv2D1gx"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import shutil\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# !pip install -U scikit-image\n",
        "# from configs import *\n",
        "\n",
        "\n",
        "def prepare_balanced_dataset():\n",
        "    def load_images_from_folder(folder, category, image_category_map):\n",
        "        images = []\n",
        "        for filename in os.listdir(folder):\n",
        "            if image_category_map.get(filename) == category:\n",
        "                img_path = os.path.join(folder, filename)\n",
        "                if os.path.isfile(img_path):\n",
        "                    images.append(filename)\n",
        "        return images\n",
        "\n",
        "    def oversample_images(images, desired_count):\n",
        "        oversampled = images[:]\n",
        "        while len(oversampled) < desired_count:\n",
        "            oversampled.append(random.choice(images))\n",
        "        return oversampled\n",
        "\n",
        "    def create_or_clear_dir(dir_path):\n",
        "        if os.path.exists(dir_path):\n",
        "            shutil.rmtree(dir_path)\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "\n",
        "    print(\"Start preparing data...\")\n",
        "    directories = [train_dir, val_dir]\n",
        "    for directory in directories:\n",
        "        create_or_clear_dir(directory)\n",
        "\n",
        "    # Read the Excel file\n",
        "    df = pd.read_excel(label_path)\n",
        "    image_category_map = pd.Series(df.Healthy.values, index=df.imagePath).to_dict()\n",
        "\n",
        "    # Get unique categories and max count\n",
        "    categories = df['Healthy'].unique()\n",
        "    max_count = df['Healthy'].value_counts().max()\n",
        "\n",
        "    # Prepare data\n",
        "    all_data = []\n",
        "    for category in categories:\n",
        "        images = load_images_from_folder(training_dataset_path, category, image_category_map)\n",
        "        oversampled_images = oversample_images(images, max_count)\n",
        "        all_data.extend([(image, category) for image in oversampled_images])\n",
        "\n",
        "    # Split data into training and val sets (80:20)\n",
        "    train_data, val_data = train_test_split(all_data, test_size=0.2, stratify=[label for _, label in all_data])\n",
        "\n",
        "    # Function to save images and return label data\n",
        "    def save_images(data, root_dir):\n",
        "        label_data = []\n",
        "        for img_filename, label in data:\n",
        "            source_path = os.path.join(training_dataset_path, img_filename)\n",
        "            target_path = os.path.join(root_dir, img_filename)\n",
        "            shutil.copy(source_path, target_path)\n",
        "            label_data.append([img_filename, label])\n",
        "        return label_data\n",
        "\n",
        "    # Save images and get label data for CSV\n",
        "    train_label_data = save_images(train_data, train_dir)\n",
        "    val_label_data = save_images(val_data, val_dir)\n",
        "\n",
        "    # Save label data to CSV\n",
        "    pd.DataFrame(train_label_data, columns=['id', 'label']).to_csv(train_labels_path, index=False)\n",
        "    pd.DataFrame(val_label_data, columns=['id', 'label']).to_csv(val_labels_path, index=False)\n",
        "    print(f\"Balanced Dataset created under {directories}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIOmmm0ND1gy",
        "outputId": "30de0077-85ec-4336-a4db-4c4b375bf613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.44.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.2)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.2)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.7)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "from matplotlib.figure import Figure\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "from matplotlib.figure import Figure\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "def plot_cam(model, image_tensor, target_layer, filename):\n",
        "    # Switch the model to evaluation mode\n",
        "    model.eval()\n",
        "    # Ensure the tensor is on the same device as the model\n",
        "    image_tensor = image_tensor.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Extract features and model output\n",
        "        features_fn = torch.nn.Sequential(*list(model.base_model.children())[:-2])\n",
        "        features = features_fn(image_tensor.unsqueeze(0))\n",
        "        output = model(image_tensor.unsqueeze(0))\n",
        "\n",
        "    # Move tensors to CPU for further processing\n",
        "    features = features.cpu()\n",
        "    output = output.cpu()\n",
        "\n",
        "    # Get weights for the target class from the fully connected layer\n",
        "    params = list(model.fc.parameters())\n",
        "    weight_softmax = np.squeeze(params[0].cpu().data.numpy())\n",
        "\n",
        "    # Compute CAM\n",
        "    class_idx = torch.topk(output, 1)[1].int()\n",
        "    cam = weight_softmax[class_idx.squeeze().item()]\n",
        "    cam = np.dot(cam, features.reshape((features.shape[1], -1)))\n",
        "    cam = cam.reshape(features.shape[2], features.shape[3])\n",
        "    cam = (cam - np.min(cam)) / (np.max(cam) - np.min(cam))\n",
        "    cam_img = np.uint8(255 * cam)\n",
        "\n",
        "    # Resize CAM to the size of the input image\n",
        "    cam_img = np.float32(Image.fromarray(cam_img).resize((image_tensor.shape[2], image_tensor.shape[1]), Image.LINEAR))\n",
        "\n",
        "    # Convert CAM to a heatmap\n",
        "    heatmap = plt.get_cmap('jet')(cam_img)[:, :, :3]\n",
        "    heatmap = Image.fromarray(np.uint8(heatmap * 255))\n",
        "\n",
        "    # Create a matplotlib figure\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(transforms.ToPILImage()(image_tensor.cpu().squeeze()))\n",
        "    ax.imshow(np.asarray(heatmap), cmap='jet', alpha=0.5, extent=(0, image_tensor.shape[2], image_tensor.shape[1], 0))\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Save the figure with 600 DPI\n",
        "    fig.savefig(filename, dpi=600, bbox_inches='tight', pad_inches=0)\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "\n",
        "def plot_occlusion(model, image_tensor, filename, occlusion_size=4, stride=1):\n",
        "\n",
        "\n",
        "    # Ensure the image tensor is on the correct device\n",
        "    image_tensor = image_tensor.to(device)\n",
        "\n",
        "    # Calculate the output height and width based on occlusion size and stride\n",
        "    output_height = int(np.ceil((224 - occlusion_size) / stride) + 1)\n",
        "    output_width = int(np.ceil((224 - occlusion_size) / stride) + 1)\n",
        "\n",
        "    # Initialize the heatmap tensor on the correct device\n",
        "    heatmap = torch.zeros((output_height, output_width), device=device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for h in range(0, 224, stride):\n",
        "            for w in range(0, 224, stride):\n",
        "                h_start = h\n",
        "                w_start = w\n",
        "                h_end = min(224, h + occlusion_size)\n",
        "                w_end = min(224, w + occlusion_size)\n",
        "\n",
        "                if (h_end - h_start) != occlusion_size or (w_end - w_start) != occlusion_size:\n",
        "                    continue\n",
        "\n",
        "                input_image = image_tensor.clone().detach()\n",
        "                input_image[:, h_start:h_end, w_start:w_end] = 0\n",
        "                input_image = input_image.to(device)  # Ensure the modified tensor is on the correct device\n",
        "\n",
        "                output = model(input_image.unsqueeze(0))\n",
        "                output = torch.nn.functional.softmax(output, dim=1)\n",
        "                prob = output.max().item()\n",
        "\n",
        "                heatmap[int(np.floor(h / stride)), int(np.floor(w / stride))] = prob\n",
        "\n",
        "    # Plot and save the heatmap\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(image_tensor.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax.imshow(heatmap.cpu(), cmap='hot', alpha=0.5, extent=(0, 224, 224, 0))\n",
        "    ax.axis('off')\n",
        "    plt.savefig(filename, dpi=600)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "!pip install shap\n",
        "\n",
        "import shap\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "from matplotlib.figure import Figure\n",
        "\n",
        "import shap\n",
        "import torch\n",
        "from torchvision.transforms import ToPILImage\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "\n",
        "# Ensure the SHAP DeepExplainer and model are compatible\n",
        "\n",
        "import shap\n",
        "import torch\n",
        "from torchvision.transforms import ToPILImage\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "from matplotlib.figure import Figure\n",
        "\n",
        "# Set up the device\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Function to plot SHAP values\n",
        "def plot_shap(model, image_tensor, filename):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # Ensure the model is in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Check if the image tensor has a batch dimension, and add it if missing\n",
        "    if image_tensor.dim() == 3:\n",
        "        # Adds a batch dimension at the start\n",
        "        image_tensor = image_tensor.unsqueeze(0)\n",
        "\n",
        "    # Move the image tensor to the same device as the model\n",
        "    image_tensor = image_tensor.to(device)\n",
        "\n",
        "    # Define a wrapper function for the model to be compatible with SHAP\n",
        "    def model_wrapper(input_data):\n",
        "        # Convert input_data to a PyTorch tensor if not already, ensuring it is on the correct device\n",
        "        input_data = torch.tensor(input_data, device=device, dtype=torch.float32)\n",
        "        # Ensure the input data has the correct shape (batch_size, channels, height, width)\n",
        "        if input_data.dim() == 3:\n",
        "            input_data = input_data.unsqueeze(0)\n",
        "        # Forward pass through the model\n",
        "        with torch.no_grad():\n",
        "            output = model(input_data)\n",
        "        # Convert output to numpy array for SHAP\n",
        "        return output.cpu().numpy()\n",
        "\n",
        "    # Assuming the image tensor shape is [batch_size, channels, height, width], like [1, 3, 224, 224]\n",
        "    input_shape = image_tensor.shape[1:]  # This gets the shape as (channels, height, width)\n",
        "\n",
        "    # Create a SHAP masker specifying the expected input shape\n",
        "    masker = shap.maskers.Image(\"input\", shape=input_shape)\n",
        "\n",
        "    # Create a SHAP explainer\n",
        "    explainer = shap.Explainer(model_wrapper, masker)\n",
        "\n",
        "    # Generate SHAP values\n",
        "    shap_values = explainer(image_tensor.cpu().numpy())\n",
        "\n",
        "    # Plotting the SHAP values\n",
        "    # Depending on your specific case, you might need to adjust how you index into shap_values\n",
        "    shap.image_plot(shap_values[0], -image_tensor.cpu().numpy())\n",
        "\n",
        "    # Save the plot\n",
        "    plt.savefig(filename)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "rUwcSuxED1g0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import models\n",
        "\n",
        "# from configs import data_dir, train_dir, train_labels_path, plot_dir\n",
        "# from configs import models_path\n",
        "# from feature_interpretability import plot_cam, plot_occlusion\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "class PCOSDataset(Dataset):\n",
        "    def __init__(self, data_dir, labels_file_path=None, transform=None):\n",
        "        self.transform = transform\n",
        "        if labels_file_path==None:\n",
        "            files = os.listdir(data_dir)\n",
        "            self.df = pd.DataFrame({'id':files, 'label':[0]*len(files)})\n",
        "        else:\n",
        "            self.df = pd.read_csv(labels_file_path)\n",
        "        self.images_dir = data_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id, label = self.df.iloc[idx]\n",
        "        img_path = os.path.join(self.images_dir, f\"{img_id}\")  # Adjust file extension as needed\n",
        "        image = Image.open(img_path)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "transformations = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.75, 1.33)),\n",
        "    transforms.RandomApply([\n",
        "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5)\n",
        "    ], p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, channel, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "\n",
        "class ModifiedResNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ModifiedResNet, self).__init__()\n",
        "        self.base_model = models.resnet50(weights=True)\n",
        "        # Modify the existing ResNet model to include SEBlocks\n",
        "        self.se_block1 = SEBlock(256)\n",
        "        self.se_block2 = SEBlock(512)\n",
        "        self.se_block3 = SEBlock(1024)\n",
        "        self.se_block4 = SEBlock(2048)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(2048, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model.conv1(x)\n",
        "        x = self.base_model.bn1(x)\n",
        "        x = self.base_model.relu(x)\n",
        "        x = self.base_model.maxpool(x)\n",
        "\n",
        "        x = self.base_model.layer1(x)\n",
        "        x = self.se_block1(x)\n",
        "        x = self.base_model.layer2(x)\n",
        "        x = self.se_block2(x)\n",
        "        x = self.base_model.layer3(x)\n",
        "        x = self.se_block3(x)\n",
        "        x = self.base_model.layer4(x)\n",
        "        x = self.se_block4(x)\n",
        "\n",
        "        x = self.base_model.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def dnn_model_train_and_eval():\n",
        "    # Create dataset instances\n",
        "    train_dataset = PCOSDataset(data_dir=train_dir, labels_file_path=train_labels_path, transform=transformations)\n",
        "    # Split train dataset\n",
        "    len_train = int(0.8 * len(train_dataset))\n",
        "    len_val = len(train_dataset) - len_train\n",
        "    train_ds, val_ds = random_split(train_dataset, [len_train, len_val])\n",
        "\n",
        "    # DataLoaders\n",
        "\n",
        "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "    val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # training and evaluation ==============================================================================================\n",
        "    def train_epoch(model, dataloader, loss_fn, optimizer, device):\n",
        "        model.train()\n",
        "        total_loss, total_correct = 0, 0\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            total_correct += (outputs.argmax(1) == targets).sum().item()\n",
        "        return total_loss / len(dataloader.dataset), total_correct / len(dataloader.dataset)\n",
        "\n",
        "    def evaluate(model, dataloader, loss_fn, device):\n",
        "        model.eval()\n",
        "        total_loss, total_correct = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in dataloader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_fn(outputs, targets)\n",
        "                total_loss += loss.item()\n",
        "                total_correct += (outputs.argmax(1) == targets).sum().item()\n",
        "        return total_loss / len(dataloader.dataset), total_correct / len(dataloader.dataset)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = ModifiedResNet(num_classes=2).to(device)\n",
        "    optimizer = Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "    train_losses, train_accuracies, val_losses, val_accuracies = [], [], [], []\n",
        "    early_stopping_patience = 20\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 0\n",
        "\n",
        "    epochs = 150\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Start epoch {epoch}\")\n",
        "        train_loss, train_acc = train_epoch(model, train_dl, loss_fn, optimizer, device)\n",
        "        val_loss, val_acc = evaluate(model, val_dl, loss_fn, device)\n",
        "        print(\n",
        "            f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "        # Store metrics for plotting\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        scheduler.step()  # Adjust the learning rate based on scheduler\n",
        "\n",
        "        # Early Stopping Check\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience = 0\n",
        "        else:\n",
        "            patience += 1\n",
        "            if patience >= early_stopping_patience:\n",
        "                print(\"Early stopping triggered\")\n",
        "                break\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss over Epochs')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accuracies, label='Train Accuracy')\n",
        "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title('Accuracy over Epochs')\n",
        "    plt.show()\n",
        "    # Save the model\n",
        "    torch.save(model.state_dict(), os.path.join(models_path, 'dnn_model.pth'))\n",
        "    # plot_interpretability_plots(model, val_dl, plot_dir, 'val')\n",
        "    # Assuming val_dl is your DataLoader for the validation dataset\n",
        "    # top_images_info = get_top_images_and_predictions(model, val_dl, device, top_k=5)\n",
        "    # save_top_images_with_predictions(top_images_info, plot_dir)\n",
        "    return model\n",
        "\n",
        "\n",
        "def dnn_predict(image_dir, labels_file_path=None, loaded_model=None, dtype='val'):\n",
        "    # Ensure the model architecture is defined exactly as before\n",
        "    if loaded_model == None:\n",
        "        loaded_model = ModifiedResNet(num_classes=2).to(device)\n",
        "        loaded_model.load_state_dict(torch.load(os.path.join(models_path, 'dnn_model.pth')))\n",
        "        # Make sure to call eval() for inference to set the model to evaluation mode\n",
        "        # loaded_model.eval()\n",
        "    test_dataset = PCOSDataset(data_dir=image_dir, labels_file_path=labels_file_path, transform=transformations)\n",
        "    test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    # Load the model parameters from the saved file\n",
        "\n",
        "\n",
        "    def predict_(model, dataloader, device):\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "        predictions = []\n",
        "        with torch.no_grad():  # Disable gradient computation\n",
        "            for inputs, _ in dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                predictions.extend(predicted.cpu().numpy())\n",
        "        return predictions\n",
        "\n",
        "    # Assuming test_dl is your DataLoader for the test dataset\n",
        "    predictions = predict_(loaded_model, test_dl, device)\n",
        "    plot_interpretability_plots(loaded_model, test_dl, plot_dir, dtype)\n",
        "    # top_images_info = get_top_images_and_predictions(loaded_model, test_dl, device, top_k=5)\n",
        "    # save_top_images_with_predictions(top_images_info, plot_dir, 'test')\n",
        "    return predictions\n",
        "\n",
        "\n",
        "def plot_interpretability_plots(model, dataloader, output_dir, type='val', no_of_plot=20):\n",
        "    model.eval()\n",
        "    top_images = []  # Store top images\n",
        "    with torch.no_grad():\n",
        "        for images, _ in dataloader:\n",
        "            outputs = model(images.to(device))\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            top_images.extend(images.cpu())\n",
        "            if len(top_images) >= no_of_plot:  # Only keep top 5 images\n",
        "                break\n",
        "\n",
        "    for i, image_tensor in enumerate(top_images[:no_of_plot]):\n",
        "        cam_filename = f\"{output_dir}/{type}_cam_plot_{i + 1}.png\"\n",
        "        occlusion_filename = f\"{output_dir}/{type}_occlusion_plot_{i + 1}.png\"\n",
        "        shap_filename  = f\"{output_dir}/{type}_shap_plot_{i + 1}.png\"\n",
        "        # Generate and save CAM plot\n",
        "        plot_cam(model, image_tensor, target_layer=model.base_model.layer4[-1], filename=cam_filename)\n",
        "\n",
        "        # Generate and save Occlusion plot\n",
        "        # plot_occlusion(model, image_tensor, filename=occlusion_filename)\n",
        "        # plot_shap(model, image_tensor, shap_filename)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_top_images_and_predictions(model, dataloader, device, top_k=5):\n",
        "    model.eval()\n",
        "    top_images_info = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, _ in dataloader:\n",
        "            images = images.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            top_prob, top_pred_classes = torch.topk(probabilities, k=1, dim=1)\n",
        "\n",
        "            for i in range(images.size(0)):\n",
        "                top_images_info.append((images[i].cpu(), top_pred_classes[i].cpu(), top_prob[i].cpu()))\n",
        "\n",
        "    # Sort by confidence and select top_k\n",
        "    top_images_info.sort(key=lambda x: x[2], reverse=True)\n",
        "    return top_images_info[:top_k]\n",
        "\n",
        "\n",
        "from PIL import ImageDraw, ImageFont\n",
        "\n",
        "\n",
        "def save_top_images_with_predictions(top_images_info, output_dir, type='val'):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Optional: specify a font for the text on the image\n",
        "    # font = ImageFont.truetype(<font-file>, 24)\n",
        "\n",
        "    for i, (image_tensor, pred_class, _) in enumerate(top_images_info):\n",
        "        image = transforms.ToPILImage()(image_tensor)\n",
        "        draw = ImageDraw.Draw(image)\n",
        "\n",
        "        # Write prediction on the image\n",
        "        # If you have a font specified, add `, font=font` to the text() call\n",
        "        text = f'Pred: {pred_class.item()}'\n",
        "        draw.text((10, 10), text, fill='red')\n",
        "\n",
        "        # Save the image\n",
        "        image.save(os.path.join(output_dir, f\"{type}_top_image_{i + 1}.png\"))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "oHSn6vZ-D1g3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "# !pip install -U scikit-image\n",
        "import pandas as pd\n",
        "import torch\n",
        "from PIL import Image\n",
        "# !pip install -U scikit-image\n",
        "from joblib import dump, load\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "from skimage.feature import local_binary_pattern\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "# !pip install keras==2.3.1\n",
        "\n",
        "model_clip = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor_clip = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "# from configs import *\n",
        "\n",
        "\n",
        "def roi_highlighter(img, radious):\n",
        "    if len(img.shape) == 2:  # Image is already grayscale\n",
        "        gray = img\n",
        "    else:\n",
        "        # Convert to grayscale\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply Gaussian blur to smooth the image and reduce noise\n",
        "    gray_blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "    # Detect circles in the image\n",
        "    # Adjust the parameters according to your needs, especially the minRadius and maxRadius\n",
        "    circles = cv2.HoughCircles(gray_blurred,\n",
        "                               cv2.HOUGH_GRADIENT,\n",
        "                               dp=1,\n",
        "                               minDist=10,\n",
        "                               param1=50,\n",
        "                               param2=30,\n",
        "                               minRadius=2,\n",
        "                               maxRadius=24 * 2)\n",
        "    # Ensure at least some circles were found\n",
        "    if circles is not None:\n",
        "        # Convert the circle parameters a, b, and r to integers\n",
        "        circles = np.uint16(np.around(circles))\n",
        "        for i in circles[0, :]:\n",
        "            # Draw the outer circle in blue color\n",
        "            cv2.circle(img, (i[0], i[1]), i[2], (255, 0, 0), 2)\n",
        "            # Optionally, draw the center of the circle\n",
        "            cv2.circle(img, (i[0], i[1]), 2, (255, 0, 0), 3)\n",
        "    return img\n",
        "\n",
        "\n",
        "def extract_lbp_features(image, s=256):\n",
        "    # Convert to grayscale\n",
        "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply LBP\n",
        "    lbp = local_binary_pattern(image_gray, P=8, R=1, method=\"uniform\")\n",
        "    lbp = lbp.flatten()\n",
        "    # Resize feature vector to a fixed size\n",
        "    fixed_size = s  # Example size, adjust as needed\n",
        "    if lbp.size < fixed_size:\n",
        "        lbp = np.concatenate([lbp, np.zeros(fixed_size - lbp.size)])\n",
        "    else:\n",
        "        lbp = lbp[:fixed_size]\n",
        "    return lbp\n",
        "\n",
        "\n",
        "def extract_orb_features(image, s):\n",
        "    orb = cv2.ORB_create()\n",
        "    keypoints, descriptors = orb.detectAndCompute(image, None)\n",
        "    # Standardizing to a fixed size (let's choose 256 for ORB)\n",
        "    if descriptors is None:\n",
        "        return np.zeros((1, s))  # Adjust size if needed\n",
        "    descriptors = descriptors.flatten()[:s]  # Taking the first 256 features\n",
        "    if descriptors.size < 256:\n",
        "        descriptors = np.concatenate([descriptors, np.zeros(s - descriptors.size)])\n",
        "    return descriptors\n",
        "\n",
        "\n",
        "def extract_sift_features(img, size=128):\n",
        "    # Assume img is already a grayscale image or convert it to grayscale\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img\n",
        "    sift = cv2.SIFT_create()\n",
        "    keypoints, descriptors = sift.detectAndCompute(gray_img, None)\n",
        "    return descriptors if descriptors is not None else np.zeros((1, size))\n",
        "\n",
        "\n",
        "def extract_clip_features(img):\n",
        "    # Convert cv2 BGR image to RGB\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    # Convert to PIL Image\n",
        "    image_pil = Image.fromarray(img_rgb)\n",
        "    processed = processor_clip(images=image_pil, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        features = model_clip.get_image_features(processed[\"pixel_values\"]).squeeze(0)\n",
        "    return features.cpu().numpy()\n",
        "\n",
        "\n",
        "def circularity_descriptor(img, max_features=10):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    ret, thresh = cv2.threshold(gray, 127, 255, 0)\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Calculate circularity for each contour and sort them\n",
        "    circularities = []\n",
        "    for cnt in contours:\n",
        "        area = cv2.contourArea(cnt)\n",
        "        perimeter = cv2.arcLength(cnt, True)\n",
        "        if perimeter == 0:\n",
        "            continue\n",
        "        circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
        "        circularities.append(circularity)\n",
        "\n",
        "    # Sort circularities and pad the descriptor if necessary\n",
        "    circularities = sorted(circularities, reverse=True)[:max_features]\n",
        "    descriptor = np.pad(circularities, (0, max_features - len(circularities)), 'constant')\n",
        "    return descriptor\n",
        "\n",
        "\n",
        "def extract_glcm_features(img):\n",
        "    # Convert to grayscale if not already\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img\n",
        "    # Calculate GLCM properties\n",
        "    glcm = graycomatrix(gray_img, distances=[5], angles=[0], levels=256, symmetric=True, normed=True)\n",
        "    features = [graycoprops(glcm, prop)[0, 0] for prop in\n",
        "                ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']]\n",
        "    return np.array(features)\n",
        "\n",
        "\n",
        "def extract_resnet50_features(img):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
        "    base_model.trainable = False  # Freeze the model for feature extraction\n",
        "\n",
        "    # Resize and preprocess the image for ResNet50\n",
        "    img_resized = cv2.resize(img, (224, 224))\n",
        "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB) if len(img.shape) == 3 else cv2.cvtColor(img_resized,\n",
        "                                                                                                    cv2.COLOR_GRAY2RGB)\n",
        "    img_array = np.expand_dims(img_rgb, axis=0)\n",
        "    preprocessed_img = preprocess_input(img_array)\n",
        "    features = base_model.predict(preprocessed_img)\n",
        "    return features.flatten()\n",
        "\n",
        "\n",
        "def combine_features(image_path, name, dt):\n",
        "    sift_features = extract_sift_features(image_path, 128).flatten()[:128]  # 88\n",
        "    clip_features = extract_clip_features(image_path).flatten()[:512]  # /91\n",
        "    glcm_features = extract_glcm_features(image_path).flatten()  # 85\n",
        "    combined_features = np.hstack(\n",
        "        (sift_features, clip_features, glcm_features))  # , lbp_features, orb_features, resnet_features))\n",
        "    return combined_features\n",
        "\n",
        "\n",
        "def ml_features_extraction():\n",
        "    train_df = pd.read_csv(train_labels_path)\n",
        "    val_df = pd.read_csv(val_labels_path)\n",
        "\n",
        "    X_train = np.array(\n",
        "        [combine_features(roi_highlighter(cv2.imread(f'{train_dir}/{row.id}'), 24), row.id, \"train\") for _, row in\n",
        "         tqdm(train_df.iterrows(), total=train_df.shape[0])])\n",
        "    y_train = train_df['label'].values\n",
        "    X_val = np.array(\n",
        "        [combine_features(roi_highlighter(cv2.imread(f'{val_dir}/{row.id}'), 24), row.id, \"val\") for _, row in\n",
        "         tqdm(val_df.iterrows(), total=val_df.shape[0])])\n",
        "    y_val = val_df['label'].values\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val = scaler.transform(X_val)\n",
        "    dump(scaler, os.path.join(models_path, 'scaler_model.joblib'))\n",
        "    # Load the scaler model from the file\n",
        "    return X_train, y_train, X_val, y_val\n",
        "\n",
        "\n",
        "def test_features_extraction(scaler=None, test_dir=test_dataset_path):\n",
        "    files = os.listdir(test_dir)\n",
        "\n",
        "    files = [os.path.join(test_dir,i) for i in files]\n",
        "    X_test = np.array(\n",
        "        [combine_features(roi_highlighter(cv2.imread(f'{row}'), 24), row, \"test\") for  row in\n",
        "         tqdm(files, total=len(files))])\n",
        "    if scaler is None:\n",
        "        scaler = load(os.path.join(models_path, 'scaler_model.joblib'))\n",
        "    X_test = scaler.transform(X_test)\n",
        "    return X_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKC5JIfc68sg"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK5BcOWBD1g4",
        "outputId": "b00fde43-7a07-4fd8-c075-9e6cdcdc1fbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.4)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.ensemble import (ExtraTreesClassifier, RandomForestClassifier, BaggingClassifier, AdaBoostClassifier)\n",
        "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.svm import NuSVC, SVC\n",
        "from sklearn.tree import ExtraTreeClassifier, DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV, Perceptron, SGDClassifier, PassiveAggressiveClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "!pip install lightgbm\n",
        "from lightgbm import LGBMClassifier\n",
        "# from xgboost import XGBClassifier\n",
        "# 'ExtraTreesClassifier', 'LabelPropagation', 'LabelSpreading', 'QuadraticDiscriminantAnalysis',\n",
        "# 'XGBClassifier', 'DecisionTreeClassifier', 'SGDClassifier', 'dnn'\n",
        "\n",
        "def ml_model_training_and_prediction(X_train, y_train, X_val):\n",
        "    # Initialize models\n",
        "    models = [\n",
        "        (\"ExtraTreesClassifier\", ExtraTreesClassifier(**{'max_depth': 25, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 250})),\n",
        "        (\"LabelPropagation\", LabelPropagation(**{'gamma': 100, 'kernel': 'rbf', 'n_neighbors': 17})),\n",
        "        (\"LabelSpreading\", LabelSpreading()),\n",
        "        (\"LGBMClassifier\", LGBMClassifier(**{'boosting_type': 'gbdt', 'learning_rate': 0.35, 'max_depth': 10, 'n_estimators': 300, 'num_leaves': 93})),\n",
        "        (\"AdaBoostClassifier\", AdaBoostClassifier()),\n",
        "        (\"QuadraticDiscriminantAnalysis\", QuadraticDiscriminantAnalysis(**{'reg_param': 0.0})),\n",
        "        # (\"XGBClassifier\", XGBClassifier(**{'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 300})),\n",
        "        (\"DecisionTreeClassifier\", DecisionTreeClassifier(**{'criterion': 'entropy', 'max_depth': 30, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 6, 'splitter': 'best'})),\n",
        "        (\"SGDClassifier\", SGDClassifier()),\n",
        "\n",
        "    ]\n",
        "\n",
        "    # Train models and make predictions\n",
        "    predictions = {}\n",
        "    for name, model in models:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_val)\n",
        "        predictions[name] = y_pred\n",
        "        print(f\"treaining :- {name}\")\n",
        "\n",
        "\n",
        "    return predictions, models\n",
        "\n",
        "\n",
        "def ml_model_pred(models, X_test):\n",
        "    predictions = {}\n",
        "    for name, model in models:\n",
        "        y_pred = model.predict(X_test)\n",
        "        predictions[name] = y_pred\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OyouBJoD1g5",
        "outputId": "35718518-d073-4289-a4b6-c218fd290341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/input/PCOSGen-test/images/\n",
            "start Deep Neural Network Model Training....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "LINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use BILINEAR or Resampling.BILINEAR instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start feature extraction for ML models....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "treaining :- ExtraTreesClassifier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "invalid value encountered in divide\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "treaining :- LabelPropagation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "invalid value encountered in divide\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "treaining :- LabelSpreading\n",
            "[LightGBM] [Info] Number of positive: 1838, number of negative: 1837\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028691 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 147824\n",
            "[LightGBM] [Info] Number of data points in the train set: 3675, number of used features: 646\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500136 -> initscore=0.000544\n",
            "[LightGBM] [Info] Start training from score 0.000544\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "treaining :- LGBMClassifier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "treaining :- AdaBoostClassifier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "treaining :- QuadraticDiscriminantAnalysis\n",
            "treaining :- DecisionTreeClassifier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "treaining :- SGDClassifier\n",
            "F1 score: 0.9268952350648317 with Best combination: ('ExtraTreesClassifier', 'LabelPropagation', 'LabelSpreading', 'LGBMClassifier', 'AdaBoostClassifier', 'QuadraticDiscriminantAnalysis', 'DecisionTreeClassifier', 'dnn')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.93       460\n",
            "           1       0.97      0.87      0.92       459\n",
            "\n",
            "    accuracy                           0.92       919\n",
            "   macro avg       0.93      0.92      0.92       919\n",
            "weighted avg       0.93      0.92      0.92       919\n",
            "\n",
            "file saved successfully  /content/drive/MyDrive/data/output/plots/val_sampleimage0758.jpg\n",
            "file saved successfully  /content/drive/MyDrive/data/output/plots/val_sampleimage1645.jpg\n",
            "file saved successfully  /content/drive/MyDrive/data/output/plots/val_sampleimage0718.jpg\n",
            "file saved successfully  /content/drive/MyDrive/data/output/plots/val_sampleimage0304.jpg\n",
            "file saved successfully  /content/drive/MyDrive/data/output/plots/val_sampleimage0949.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "LINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use BILINEAR or Resampling.BILINEAR instead.\n",
            "invalid value encountered in divide\n",
            "invalid value encountered in divide\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file saved successfully  /content/drive/MyDrive/data/output/plots/test_sampleimage10906.jpg\n",
            "file saved successfully  /content/drive/MyDrive/data/output/plots/test_sampleimage10536.jpg\n",
            "file saved successfully  /content/drive/MyDrive/data/output/plots/test_sampleimage10234.jpg\n",
            "file saved successfully  /content/drive/MyDrive/data/output/plots/test_sampleimage10603.jpg\n",
            "file saved successfully  /content/drive/MyDrive/data/output/plots/test_sampleimage10466.jpg\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "\n",
        "class PCOSTraning:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.models = None\n",
        "        self.dnn_model = None\n",
        "\n",
        "    def put_text_on_image(self, image_path, text, output_path):\n",
        "      image = Image.open(image_path)\n",
        "      # Prepare the drawing context\n",
        "      draw = ImageDraw.Draw(image)\n",
        "      # Position for the text\n",
        "      text_position = (25, 25)\n",
        "      # Text color (RGBA)\n",
        "      text_color = (255, 255, 255, 128)  # semi-transparent white text\n",
        "      # Draw the text on the image\n",
        "      draw.text(text_position, text, fill=text_color)\n",
        "      # Save or display the image\n",
        "      image.save(output_path, dpi=(600, 600))\n",
        "\n",
        "      print(\"file saved successfully \" , output_path)\n",
        "\n",
        "    def plot_top_images(self, image_dir, y_pred, val_labels_path=None, dtype='val'):\n",
        "      files = os.listdir(image_dir)\n",
        "      df_1 = []\n",
        "      df_0 = []\n",
        "      if val_labels_path:\n",
        "        df = pd.read_csv(val_labels_path)\n",
        "        df['y_pred'] = y_pred\n",
        "        df['label']= df['label'].apply(str)\n",
        "        df['y_pred']= df['y_pred'].apply(str)\n",
        "        df= df[df['label']==df['y_pred']]\n",
        "        df_1 = df[df['y_pred']==\"1\"]['id'].to_list()[:2]\n",
        "        df_0 = df[df['y_pred']==\"0\"]['id'].to_list()[:3]\n",
        "      else:\n",
        "        df = pd.DataFrame({'id':files, 'label':y_pred})\n",
        "        df['label']= df['label'].apply(str)\n",
        "        df_1 = df[df['label']==\"1\"]['id'].to_list()[:2]\n",
        "        df_0 = df[df['label']==\"0\"]['id'].to_list()[:3]\n",
        "      z= {'class_1':df_1, 'class_0':df_0}\n",
        "      for c in z:\n",
        "        for img in z[c]:\n",
        "          self.put_text_on_image(\n",
        "              os.path.join(image_dir, img),\n",
        "              c, os.path.join(plot_dir, f'{dtype}_sample'+img)\n",
        "          )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def dnn_and_ml_ensemble_eval(self, predictions, y_val, models):\n",
        "\n",
        "        ensemble_pred = []\n",
        "        for j in range(len(models), len(models) + 1):  # Start from 1 to include at least one model besides GaussianNB\n",
        "            comb_scores = {}\n",
        "            for combo in itertools.combinations([model[0] for model in models],\n",
        "                                                j - 1):  # Adjust to j - 1 to leave space for GaussianNB\n",
        "                combo = combo + (\"dnn\",)  # Always include GaussianNB in the combination\n",
        "                # Ensemble prediction by majority vote, now including GaussianNB\n",
        "                ensemble_pred = np.array([np.bincount(\n",
        "                    [predictions[model_name][i] for model_name in combo]\n",
        "                ).argmax() for i in range(len(y_val))])\n",
        "                f1 = f1_score(y_val, ensemble_pred, average='macro')\n",
        "                comb_scores[combo] = f1\n",
        "\n",
        "            # Sort combinations by F1 score\n",
        "            sorted_comb_scores = sorted(comb_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            # Print the best combination for this round\n",
        "            best_combo, best_score = sorted_comb_scores[0]\n",
        "            print(f\"F1 score: {best_score} with Best combination: {best_combo}\")\n",
        "\n",
        "        print(classification_report(y_val, ensemble_pred))\n",
        "        return ensemble_pred\n",
        "\n",
        "    def dnn_and_ml_ensemble_pred(self, predictions, models):\n",
        "        ensemble_pred=[]\n",
        "        for j in range(len(models), len(models) + 1):  # Start from 1 to include at least one model besides GaussianNB\n",
        "            comb_scores = {}\n",
        "            for combo in itertools.combinations([model[0] for model in models],\n",
        "                                                j - 1):  # Adjust to j - 1 to leave space for GaussianNB\n",
        "                combo = combo + (\"dnn\",)  # Always include GaussianNB in the combination\n",
        "                # Ensemble prediction by majority vote, now including GaussianNB\n",
        "                ensemble_pred = np.array([np.bincount(\n",
        "                    [predictions[model_name][i] for model_name in combo]\n",
        "                ).argmax() for i in range(len(predictions['dnn']))])\n",
        "        return ensemble_pred\n",
        "\n",
        "    def main(self):\n",
        "        prepare_balanced_dataset()\n",
        "        print(\"start Deep Neural Network Model Training....\")\n",
        "        dnn_model = dnn_model_train_and_eval()\n",
        "        dnn_model=None\n",
        "        dnn_y_pred = dnn_predict(val_dir, val_labels_path, dnn_model, dtype='val')\n",
        "        print(\"start feature extraction for ML models....\")\n",
        "\n",
        "        X_train, y_train, X_val, y_val = ml_features_extraction()\n",
        "        print(\"start ML models training....\")\n",
        "\n",
        "        predictions, models = ml_model_training_and_prediction(X_train, y_train, X_val)\n",
        "        predictions['dnn'] = dnn_y_pred\n",
        "        ensemble_pred = self.dnn_and_ml_ensemble_eval(predictions, y_val, models)\n",
        "        self.models = models\n",
        "        self.dnn_model = dnn_model\n",
        "        self.plot_top_images(val_dir, ensemble_pred, val_labels_path, dtype='val')\n",
        "\n",
        "    def test_label_prediction(self, test_dir=test_dataset_path):\n",
        "\n",
        "        dnn_test_prediction = dnn_predict(test_dir, labels_file_path=None, loaded_model=self.dnn_model, dtype = 'test')\n",
        "        X_test = test_features_extraction(scaler=None, test_dir=test_dataset_path)\n",
        "\n",
        "\n",
        "        ml_test_predictions = ml_model_pred(self.models, X_test)\n",
        "        ml_test_predictions['dnn'] = dnn_test_prediction\n",
        "        predictions = self.dnn_and_ml_ensemble_pred(ml_test_predictions, self.models)\n",
        "        df = pd.DataFrame({\"S.No.\": list(range(1,len(predictions)+1)),\"Image Path\": os.listdir(test_dir), \"Predicted Class Label\": predictions})\n",
        "        df.to_excel(result_submission_file, index=False)\n",
        "        self.plot_top_images(test_dir, predictions, None, dtype='test')\n",
        "\n",
        "\n",
        "\n",
        "obj = PCOSTraning()\n",
        "obj.main()\n",
        "obj.test_label_prediction(test_dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "j8G7SNLtD1g6"
      },
      "outputs": [],
      "source": [
        "# F1 score: 0.7285210596531351 with Best combination: ('dnn',)\n",
        "# F1 score: 0.8466243868458481 with Best combination: ('LabelPropagation', 'dnn')\n",
        "# F1 score: 0.9301087535173778 with Best combination: ('LabelPropagation', 'LabelSpreading', 'dnn')\n",
        "# F1 score: 0.9301087535173778 with Best combination: ('ExtraTreesClassifier', 'LabelPropagation', 'LabelSpreading', 'dnn')\n",
        "# F1 score: 0.9302579280381722 with Best combination: ('ExtraTreesClassifier', 'LabelPropagation', 'LabelSpreading', 'AdaBoostClassifier', 'dnn')\n",
        "# F1 score: 0.9324258294670728 with Best combination: ('ExtraTreesClassifier', 'LabelPropagation', 'LabelSpreading', 'LGBMClassifier', 'AdaBoostClassifier', 'dnn')\n",
        "# F1 score: 0.9323873399215865 with Best combination: ('ExtraTreesClassifier', 'LabelPropagation', 'LabelSpreading', 'QuadraticDiscriminantAnalysis', 'AdaBoostClassifier', 'PassiveAggressiveClassifier', 'dnn')\n",
        "# add Codeadd Markdown\n",
        "\n",
        "# F1 score: 0.7445257035326318 with Best combination: ('dnn',)\n",
        "# F1 score: 0.8477845870756597 with Best combination: ('LabelPropagation', 'dnn')\n",
        "# F1 score: 0.9301087535173778 with Best combination: ('LabelPropagation', 'LabelSpreading', 'dnn')\n",
        "# F1 score: 0.9301087535173778 with Best combination: ('ExtraTreesClassifier', 'LabelPropagation', 'LabelSpreading', 'dnn')\n",
        "# F1 score: 0.9301087535173778 with Best combination: ('LabelPropagation', 'LabelSpreading', 'QuadraticDiscriminantAnalysis', 'DecisionTreeClassifier', 'dnn')\n",
        "# F1 score: 0.930220197418375 with Best combination: ('ExtraTreesClassifier', 'LabelPropagation', 'LabelSpreading', 'LGBMClassifier', 'AdaBoostClassifier', 'dnn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "b5QOi1onD1hC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kaggle": {
      "accelerator": "tpu1vmV38",
      "dataSources": [
        {
          "datasetId": 4489545,
          "sourceId": 7692601,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30646,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}